{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f80e3-c82a-4ab5-b7c1-14403af52334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "import czifile\n",
    "from tqdm.notebook import tqdm  # âœ… Notebook-friendly progress bar\n",
    "from monai.inferers import sliding_window_inference\n",
    "from tnia.deeplearning.dl_helper import quantile_normalization\n",
    "import torch.nn.functional as F\n",
    "np.float_ = np.float32\n",
    "\n",
    "# --------------------------- CONFIGURATION --------------------------- #\n",
    "\n",
    "BASE_PATH = Path(r'C:/Users/Alex/Desktop/Mailis')\n",
    "DATA_DIR = BASE_PATH / \"data\"\n",
    "MODEL_PATH = BASE_PATH / \"models\" / \"full_brain.pth\"\n",
    "OUTPUT_DIR = BASE_PATH / \"Brain_volume\"\n",
    "\n",
    "ROI_SIZE = 1024\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "EXPORT_MODE = \"classification\"  # \"classification\" or \"probability\"\n",
    "EXPORT_CLASSES = [0, 1, 2]\n",
    "\n",
    "SUPPORTED_EXTENSIONS = [\n",
    "    \"*.czi\", \"*.tif\", \"*.tiff\", \"*.ome.tif\", \"*.ome.tiff\", \"*.btf\", \"*.ome.btf\"\n",
    "]\n",
    "\n",
    "# --------------------------- INITIALIZATION --------------------------- #\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(MODEL_PATH, weights_only=False).to(device)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------------------------- IMAGE LOADING --------------------------- #\n",
    "\n",
    "def load_image(path: Path) -> np.ndarray:\n",
    "    ext = path.suffix.lower()\n",
    "    if ext == \".czi\":\n",
    "        image = czifile.imread(path)\n",
    "    elif ext in [\".tif\", \".tiff\", \".ome.tif\", \".ome.tiff\", \".btf\", \".ome.btf\"]:\n",
    "        image = tifffile.imread(path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {ext}\")\n",
    "    \n",
    "    image = np.squeeze(image)\n",
    "\n",
    "    if image.ndim != 3:\n",
    "        raise ValueError(f\"Expected 3D image (Z, Y, X), got shape {image.shape}\")\n",
    "    \n",
    "    return image\n",
    "\n",
    "# --------------------------- SLICE PREDICTION --------------------------- #\n",
    "\n",
    "def predict(image_2d: np.ndarray, model: torch.nn.Module) -> np.ndarray:\n",
    "    image = quantile_normalization(image_2d).astype(np.float32)\n",
    "    tensor = torch.from_numpy(image).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = sliding_window_inference(\n",
    "            tensor,\n",
    "            roi_size=ROI_SIZE,\n",
    "            sw_batch_size=BATCH_SIZE,\n",
    "            predictor=model\n",
    "        )\n",
    "        probabilities = F.softmax(logits, dim=1)\n",
    "\n",
    "    return probabilities.squeeze(0).cpu().numpy()\n",
    "\n",
    "# --------------------------- PROCESS A SINGLE FILE --------------------------- #\n",
    "\n",
    "def process_file(image_path: Path, file_index: int, total_files: int):\n",
    "    \"\"\"\n",
    "    Processes a full 3D image stack: applies inference slice by slice,\n",
    "    and writes the output directly to disk as OME-TIFF (C, Z, Y, X).\n",
    "    \"\"\"\n",
    "    print(f\"\\n[{file_index + 1}/{total_files}] Processing: {image_path.name}\")\n",
    "    image_stack = load_image(image_path)\n",
    "    depth, height, width = image_stack.shape\n",
    "\n",
    "    test_probs = predict(image_stack[0], model)\n",
    "    total_classes = test_probs.shape[0]\n",
    "\n",
    "    for cls in EXPORT_CLASSES:\n",
    "        if cls < 0 or cls >= total_classes:\n",
    "            raise ValueError(f\"Invalid class index {cls}. Model returns {total_classes} classes.\")\n",
    "\n",
    "    suffix = \"classification\" if EXPORT_MODE == \"classification\" else \"probability\"\n",
    "    save_path = OUTPUT_DIR / f\"{image_path.stem}_{suffix}.ome.tif\"\n",
    "\n",
    "    with tifffile.TiffWriter(save_path, bigtiff=True) as tif:\n",
    "        for z in tqdm(range(depth), desc=f\"Predicting slices ({depth})\", leave=False):\n",
    "            prob_map = predict(image_stack[z], model)\n",
    "\n",
    "            if EXPORT_MODE == \"probability\":\n",
    "                for cls in EXPORT_CLASSES:\n",
    "                    prob = (prob_map[cls] * 255).astype(np.uint8)\n",
    "                    tif.write(\n",
    "                        prob[np.newaxis, np.newaxis, :, :],\n",
    "                        photometric='minisblack',\n",
    "                        metadata={'axes': 'CZYX'},\n",
    "                        contiguous=True\n",
    "                    )\n",
    "\n",
    "            elif EXPORT_MODE == \"classification\":\n",
    "                class_map = np.argmax(prob_map, axis=0)\n",
    "                for cls in EXPORT_CLASSES:\n",
    "                    binary_mask = (class_map == cls).astype(np.uint8)\n",
    "                    tif.write(\n",
    "                        binary_mask[np.newaxis, np.newaxis, :, :],\n",
    "                        photometric='minisblack',\n",
    "                        metadata={'axes': 'CZYX'},\n",
    "                        contiguous=True\n",
    "                    )\n",
    "\n",
    "    print(f\"Saved output to: {save_path}\")\n",
    "\n",
    "# --------------------------- MAIN SCRIPT --------------------------- #\n",
    "\n",
    "def main():\n",
    "    input_files = []\n",
    "    for ext in SUPPORTED_EXTENSIONS:\n",
    "        input_files.extend(DATA_DIR.glob(ext))\n",
    "    input_files = sorted(input_files)\n",
    "\n",
    "    if not input_files:\n",
    "        print(\"No input image files found in the specified folder.\")\n",
    "        return\n",
    "\n",
    "    print(f\"{len(input_files)} image file(s) detected.\")\n",
    "\n",
    "    for idx, image_file in enumerate(tqdm(input_files, desc=\"Processing files\")):\n",
    "        process_file(image_file, idx, len(input_files))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
